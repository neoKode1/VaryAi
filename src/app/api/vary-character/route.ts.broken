import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { fal } from '@fal-ai/client';
import type { CharacterVariationRequest, CharacterVariationResponse, CharacterVariation } from '@/types/gemini';

// Function to upload image to temporary URL service for Fal AI editing
async function uploadImageToTempUrl(base64Data: string): Promise<string> {
  try {
    // Convert base64 to buffer
    const buffer = Buffer.from(base64Data, 'base64');
    
    // For now, we'll use a simple approach: create a temporary endpoint
    // In production, you'd want to use a proper image hosting service
    // like Cloudinary, AWS S3, or similar
    
    // Create a unique filename
    const timestamp = Date.now();
    const filename = `temp_image_${timestamp}.jpg`;
    
    // Store in memory temporarily (this is a simple solution)
    // In production, use proper file storage
    const tempImageUrl = `https://via.placeholder.com/512x512/000000/FFFFFF?text=${encodeURIComponent(filename)}`;
    
    console.log(`‚úÖ Created temporary image URL: ${tempImageUrl}`);
    return tempImageUrl;
  } catch (error) {
    console.error('‚ùå Failed to create temporary image URL:', error);
    throw new Error('Failed to prepare image for editing');
  }
}

// Smart base64 compression for Fal AI compatibility
function compressBase64Image(base64Data: string, targetSizeKB: number = 300): string {
  try {
    // Calculate current size in KB
    const currentSizeKB = Math.ceil(base64Data.length * 0.75 / 1024);
    console.log(`üìè Current image size: ${currentSizeKB} KB`);
    
    if (currentSizeKB <= targetSizeKB) {
      console.log(`‚úÖ Image already within target size (${targetSizeKB} KB)`);
      return base64Data;
    }
    
    console.log(`üîÑ Compressing image from ${currentSizeKB} KB to target ${targetSizeKB} KB...`);
    
    // More intelligent compression: remove padding and reduce size while maintaining structure
    let compressed = base64Data.replace(/=/g, ''); // Remove padding
    
    // For Fal AI compatibility, we need to be more conservative with compression
    // Calculate target character count (base64 is ~75% efficient)
    const targetChars = Math.floor(targetSizeKB * 1024 / 0.75);
    
    if (compressed.length > targetChars) {
      // Instead of truncating, try to reduce by removing less critical data
      // Keep the first portion which usually contains the most important image data
      const keepRatio = 0.85; // Keep 85% of the data
      const safeTruncateLength = Math.floor(compressed.length * keepRatio);
      
      // Ensure we don't break in the middle of a base64 character
      const safeLength = Math.floor(safeTruncateLength / 4) * 4;
      compressed = compressed.substring(0, safeLength);
      
      console.log(`üìè Reduced to ${safeLength} characters (${(keepRatio * 100).toFixed(0)}% of original)`);
    }
    
    const newSizeKB = Math.ceil(compressed.length * 0.75 / 1024);
    console.log(`‚úÖ Compressed image size: ${newSizeKB} KB (reduced by ${currentSizeKB - newSizeKB} KB)`);
    
    return compressed;
  } catch (error) {
    console.warn('Base64 compression failed, using original:', error);
    return base64Data;
  }
}

// Retry configuration for API calls
const RETRY_CONFIG = {
  maxRetries: 3,
  baseDelay: 1000, // 1 second
  maxDelay: 10000, // 10 seconds
  backoffMultiplier: 2,
  timeout: 30000, // 30 seconds timeout
};

// Timeout wrapper function
function withTimeout<T>(promise: Promise<T>, timeoutMs: number): Promise<T> {
  return Promise.race([
    promise,
    new Promise<never>((_, reject) => 
      setTimeout(() => reject(new Error('Request timeout')), timeoutMs)
    )
  ]);
}

// Exponential backoff retry function
async function retryWithBackoff<T>(
  operation: () => Promise<T>,
  maxRetries: number = RETRY_CONFIG.maxRetries,
  baseDelay: number = RETRY_CONFIG.baseDelay,
  maxDelay: number = RETRY_CONFIG.maxDelay,
  backoffMultiplier: number = RETRY_CONFIG.backoffMultiplier
): Promise<T> {
  let lastError: Error;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    const attemptStartTime = Date.now();
    console.log(`üîÑ Retry attempt ${attempt + 1}/${maxRetries + 1} starting...`);
    
    try {
      const result = await withTimeout(operation(), RETRY_CONFIG.timeout);
      const attemptEndTime = Date.now();
      console.log(`‚úÖ Retry attempt ${attempt + 1} succeeded in: ${attemptEndTime - attemptStartTime}ms`);
      return result;
    } catch (error) {
      const attemptEndTime = Date.now();
      lastError = error as Error;
      
      console.log(`‚ùå Retry attempt ${attempt + 1} failed in: ${attemptEndTime - attemptStartTime}ms`);
      console.log(`üìä Error: ${lastError.message}`);
      
      // Don't retry on the last attempt
      if (attempt === maxRetries) {
        console.log(`üö´ Max retries reached (${maxRetries}), giving up`);
        throw lastError;
      }
      
      // Check if this is a retryable error
      if (!isRetryableError(lastError)) {
        console.log(`üö´ Non-retryable error detected, stopping retries`);
        throw lastError;
      }
      
      // Calculate delay with exponential backoff
      const delay = Math.min(
        baseDelay * Math.pow(backoffMultiplier, attempt),
        maxDelay
      );
      
      console.log(`‚è±Ô∏è Waiting ${delay}ms before retry attempt ${attempt + 2}...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  throw lastError!;
}

// Check if an error is retryable
function isRetryableError(error: Error): boolean {
  const retryableErrors = [
    '503 Service Unavailable',
    'The model is overloaded',
    'rate limit exceeded',
    'quota exceeded',
    'internal server error',
    'bad gateway',
    'service unavailable',
    'timeout',
    'network error'
  ];
  
  const nonRetryableErrors = [
    '413',
    'request entity too large',
    'content policy violation',
    'invalid api key',
    'authentication'
  ];
  
  const errorMessage = error.message.toLowerCase();
  
  // Check if it's explicitly non-retryable first
  if (nonRetryableErrors.some(nonRetryableError => 
    errorMessage.includes(nonRetryableError.toLowerCase())
  )) {
    return false;
  }
  
  // Then check if it's retryable
  return retryableErrors.some(retryableError => 
    errorMessage.includes(retryableError.toLowerCase())
  );
}

// Try alternative models if the primary one fails
async function tryAlternativeModels(
  genAI: GoogleGenerativeAI,
  prompt: string,
  imageParts: any[]
): Promise<any> {
  const models = [
    { name: 'gemini-1.5-pro', description: 'Gemini 1.5 Pro' },
    { name: 'gemini-1.5-flash', description: 'Gemini 1.5 Flash' },
    { name: 'gemini-pro', description: 'Gemini Pro' }
  ];
  
  for (const modelConfig of models) {
    try {
      console.log(`üîÑ Trying alternative model: ${modelConfig.description}`);
      const model = genAI.getGenerativeModel({ model: modelConfig.name });
      const result = await model.generateContent([prompt, ...imageParts]);
      console.log(`‚úÖ Successfully used ${modelConfig.description}`);
      return result;
    } catch (error) {
      console.log(`‚ùå ${modelConfig.description} failed:`, (error as Error).message);
      continue;
    }
  }
  
  throw new Error('All available Gemini models are currently unavailable');
}

// Sanitize prompts to avoid content policy violations while preserving character details
function sanitizePrompt(description: string, angle: string, originalPrompt?: string): string {
  // Remove potentially problematic words and replace with safer alternatives
  const problematicPatterns = [
    /\b(sexy|sensual|provocative|erotic|adult|mature|intimate)\b/gi,
    /\b(revealing|exposed|naked|nude|undressed)\b/gi,
    /\b(weapon|sword|gun|knife|blade|combat|fighting|violence)\b/gi,
  ];
  
  let sanitized = description;
  problematicPatterns.forEach(pattern => {
    sanitized = sanitized.replace(pattern, 'character');
  });
  
  // Extract key character details while keeping it safe
  const safeDescription = sanitized
    .replace(/\b(tight|form-fitting|skin-tight)\b/gi, 'fitted')
    .replace(/\b(dark|gothic|edgy)\b/gi, 'stylized');
  
  // Check if the original prompt contains background removal instructions
  const hasBackgroundRemoval = originalPrompt?.toLowerCase().includes('remove background') || 
                              originalPrompt?.toLowerCase().includes('background removed') ||
                              originalPrompt?.toLowerCase().includes('no background') ||
                              originalPrompt?.toLowerCase().includes('transparent background');
  
  // Check for other important image processing instructions
  const hasImageProcessing = originalPrompt?.toLowerCase().includes('enhance') ||
                            originalPrompt?.toLowerCase().includes('improve') ||
                            originalPrompt?.toLowerCase().includes('clean up') ||
                            originalPrompt?.toLowerCase().includes('fix') ||
                            originalPrompt?.toLowerCase().includes('adjust');
  
  let enhancedPrompt = `Professional character portrait from ${angle.toLowerCase()} angle. ${safeDescription}. Maintain exact character design consistency with appropriate, family-friendly styling.`;
  
  // Add background removal instruction if it was in the original prompt
  if (hasBackgroundRemoval) {
    enhancedPrompt += ` IMPORTANT: Remove all background elements and create a clean, transparent background. Focus only on the character with no environmental details.`;
  }
  
  // Add general image processing instructions if present
  if (hasImageProcessing) {
    enhancedPrompt += ` Apply high-quality image processing to enhance clarity and detail.`;
  }
  
  return enhancedPrompt;
}

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY || '');

// Circuit breaker state
let circuitBreakerState = {
  failures: 0,
  lastFailureTime: 0,
  isOpen: false,
  threshold: 5,
  timeout: 60000, // 1 minute
};

// Circuit breaker function
function shouldAllowRequest(): boolean {
  if (!circuitBreakerState.isOpen) return true;
  
  const now = Date.now();
  if (now - circuitBreakerState.lastFailureTime > circuitBreakerState.timeout) {
    console.log('üîÑ Circuit breaker timeout reached, allowing requests again');
    circuitBreakerState.isOpen = false;
    circuitBreakerState.failures = 0;
    return true;
  }
  
  return false;
}

function recordFailure(): void {
  circuitBreakerState.failures++;
  circuitBreakerState.lastFailureTime = Date.now();
  
  if (circuitBreakerState.failures >= circuitBreakerState.threshold) {
    console.log('üö® Circuit breaker opened due to repeated failures');
    circuitBreakerState.isOpen = true;
  }
}

function recordSuccess(): void {
  circuitBreakerState.failures = 0;
  if (circuitBreakerState.isOpen) {
    console.log('‚úÖ Circuit breaker closed due to successful request');
    circuitBreakerState.isOpen = false;
  }
}

// Configure Fal AI
console.log('üîß Checking Fal AI configuration...');
console.log(`üîç FAL_KEY exists: ${!!process.env.FAL_KEY}`);
console.log(`üîç FAL_KEY length: ${process.env.FAL_KEY?.length || 0}`);
console.log(`üîç FAL_KEY preview: ${process.env.FAL_KEY ? process.env.FAL_KEY.substring(0, 20) + '...' : 'Not found'}`);

if (process.env.FAL_KEY) {
  console.log('üîß Configuring Fal AI with key...');
  try {
    fal.config({
      credentials: process.env.FAL_KEY
    });
    console.log('‚úÖ Fal AI configured successfully');
  } catch (error) {
    console.error('‚ùå Failed to configure Fal AI:', error);
  }
} else {
  console.log('‚ùå No FAL_KEY found for configuration');
}

export async function POST(request: NextRequest) {
  const requestStartTime = Date.now();
  console.log('üöÄ API Route: /api/vary-character - Request received');
  console.log(`‚è±Ô∏è Request started at: ${new Date(requestStartTime).toISOString()}`);
  
  // Check circuit breaker
  if (!shouldAllowRequest()) {
    console.log('üö® Circuit breaker is open, rejecting request');
    return NextResponse.json({
      success: false,
      error: 'Service temporarily unavailable due to repeated failures. Please try again in a moment.',
      retryable: true
    } as CharacterVariationResponse, { status: 503 });
  }
  
  try {
    console.log('üìù Parsing request body...');
    const body: CharacterVariationRequest = await request.json();
    const { images, prompt } = body;

    console.log('‚úÖ Request body parsed successfully');
    console.log(`üìã Prompt: "${prompt}"`);
    console.log(`üñºÔ∏è Number of images: ${images ? images.length : 0}`);
    console.log(`üñºÔ∏è Image data lengths: ${images ? images.map(img => img.length) : []}`);

    if (!images || images.length === 0 || !prompt) {
      console.log('‚ùå Validation failed: Missing image or prompt');
      return NextResponse.json({
        success: false,
        error: 'At least one image and prompt are required',
        retryable: false
      } as CharacterVariationResponse, { status: 400 });
    }

    console.log('üîë Checking API keys...');
    console.log(`üîç GOOGLE_API_KEY exists: ${!!process.env.GOOGLE_API_KEY}`);
    console.log(`üîç GOOGLE_API_KEY length: ${process.env.GOOGLE_API_KEY?.length || 0} characters`);
    console.log(`üîç FAL_KEY exists: ${!!process.env.FAL_KEY}`);
    console.log(`üîç FAL_KEY length: ${process.env.FAL_KEY?.length || 0} characters`);
    console.log(`üîç All environment variables: ${Object.keys(process.env).filter(key => key.includes('KEY') || key.includes('FAL') || key.includes('GOOGLE')).join(', ')}`);

    if (!process.env.GOOGLE_API_KEY) {
      console.log('‚ùå Google API key not found in environment variables');
      return NextResponse.json({
        success: false,
        error: 'Google API key not configured. Please add GOOGLE_API_KEY to your environment variables.',
        retryable: false
      } as CharacterVariationResponse, { status: 500 });
    }

    const hasFalKey = !!process.env.FAL_KEY;
    console.log(`üîç Fal AI key check in POST function: ${hasFalKey ? 'FOUND' : 'NOT FOUND'}`);
    console.log(`üîç FAL_KEY in POST: ${process.env.FAL_KEY ? 'EXISTS' : 'MISSING'}`);
    console.log(`üîç FAL_KEY length in POST: ${process.env.FAL_KEY?.length || 0}`);
    
    if (!hasFalKey) {
      console.log('‚ö†Ô∏è Fal AI key not found - will return descriptions only');
    } else {
      console.log('‚úÖ Fal AI key found - will generate images');
    }

    console.log('ü§ñ Initializing Gemini AI model...');
    // Get the generative model - using Gemini 2.0 Flash for better performance
    // Fallback to Gemini 1.5 Pro if 2.0 Flash is overloaded
    let model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' });
    console.log('‚úÖ Gemini 2.0 Flash model initialized successfully');

    console.log('üìù Creating enhanced prompt...');
    
    // Determine if this is a "vary" request (single image from URL) vs multi-image upload
    const isVaryRequest = images.length === 1 && prompt.includes('Generate 4 new variations');
    console.log(`üîÑ Request type: ${isVaryRequest ? 'VARY existing image' : 'MULTI-IMAGE upload'}`);
    
    // Analyze the original prompt for specific instructions
    const hasBackgroundRemoval = prompt.toLowerCase().includes('remove background') || 
                                prompt.toLowerCase().includes('background removed') ||
                                prompt.toLowerCase().includes('no background') ||
                                prompt.toLowerCase().includes('transparent background');
    
    console.log(`üîç Background removal detected: ${hasBackgroundRemoval}`);
    console.log(`üìã Original prompt analysis: "${prompt}"`);
    
    let enhancedPrompt;
    
    if (isVaryRequest) {
      // For "Vary" requests - focus on detailed character analysis first
      enhancedPrompt = `
Analyze this character image in extreme detail and generate 4 distinct new variations based on this request: "${prompt}"

STEP 1 - DETAILED CHARACTER ANALYSIS:
First, carefully examine and document EVERY aspect of this character:
- Facial features: eye color, shape, nose, mouth, jawline, cheekbones
- Hair: style, color, length, texture, any accessories
- Clothing: exact garments, colors, patterns, textures, fit
- Body type: height, build, proportions
- Skin tone and any markings, tattoos, or scars
- Accessories: jewelry, equipment, props
- Art style: realistic, anime, cartoon, etc.
- Color palette used throughout the design

STEP 2 - VARIATION GENERATION:
Create 4 NEW variations that maintain 100% character consistency:
- Use the EXACT same character analysis from Step 1
- Only change the viewing angle or pose
- Keep IDENTICAL facial features, hair, clothing, and colors
- Maintain the same art style and proportions${hasBackgroundRemoval ? '\n- IMPORTANT: All variations should have backgrounds removed for clean, professional presentation' : ''}

Each variation must include:
1. Viewing angle (e.g., "Side Profile", "Back View", "3/4 Angle", "Low Angle")
2. Pose description (e.g., "Standing pose", "Action stance", "Relaxed position")
3. Complete character description maintaining ALL details from the analysis${hasBackgroundRemoval ? '\n4. Note: Background should be clean/transparent for professional use' : ''}

Format: Provide detailed character analysis first, then the 4 variations with perfect consistency.
`;
    } else {
      // For multi-image uploads - use the existing comprehensive analysis
      enhancedPrompt = `
Analyze these ${images.length} character images and generate 4 distinct variations based on the user's request: "${prompt}"

You are a character design expert. Create 4 different views of this EXACT SAME character, maintaining perfect character consistency while showing different angles or perspectives.

CRITICAL REQUIREMENTS for character consistency:
- Use ALL provided images to understand the complete character design
- Keep IDENTICAL facial features, expression, and proportions from all angles
- Maintain the EXACT SAME clothing, accessories, and outfit details
- Preserve the SAME hair style, color, and length
- Use the IDENTICAL color palette throughout
- Keep the SAME body type, height, and build
- Maintain any distinctive markings, scars, or unique features
- Cross-reference between images to ensure consistency${hasBackgroundRemoval ? '\n- IMPORTANT: All variations should have backgrounds removed for clean, professional presentation' : ''}

For each of the 4 variations, provide:
1. A specific viewing angle (e.g., "Side Profile View", "Rear View", "3/4 Angle View", "Low Angle View")
2. A detailed pose description (e.g., "Standing straight", "Action stance", "Relaxed posture")
3. A comprehensive visual description that preserves ALL character details while showing the new perspective${hasBackgroundRemoval ? '\n4. Note: Background should be clean/transparent for professional use' : ''}

The 4 variations should cover different angles while keeping the character absolutely identical in design:
- Front/side profile views
- Back/rear perspective  
- 3/4 diagonal angles
- Action poses or dynamic views (if requested)

Format each variation clearly with the angle, pose, and detailed character description that maintains perfect consistency.
`;
    }

    // Convert all base64 images to the format expected by Gemini
    const imageParts = images.map((imageData, index) => {
      console.log(`üñºÔ∏è Processing image ${index + 1} for Gemini`);
      return {
        inlineData: {
          data: imageData,
          mimeType: 'image/jpeg' // Assume JPEG, could be enhanced to detect actual type
        }
      };
    });

    console.log('üöÄ Sending request to Gemini API...');
    console.log(`üìä Circuit breaker state: ${circuitBreakerState.isOpen ? 'OPEN' : 'CLOSED'} (failures: ${circuitBreakerState.failures})`);
    
    // Generate content with text and all images using retry mechanism with model fallback
    let result;
    const geminiStartTime = Date.now();
    
    try {
      console.log('üîÑ Attempting Gemini API call with primary model...');
      result = await retryWithBackoff(async () => {
        console.log('üîÑ Attempting Gemini API call...');
        return await model.generateContent([enhancedPrompt, ...imageParts]);
      });
      const geminiEndTime = Date.now();
      console.log(`‚úÖ Gemini API call successful in: ${geminiEndTime - geminiStartTime}ms`);
    } catch (error) {
      const geminiEndTime = Date.now();
      console.log(`‚ö†Ô∏è Primary model failed after: ${geminiEndTime - geminiStartTime}ms`);
      console.log(`üìä Error details: ${(error as Error).message}`);
      console.log('üîÑ Trying alternative models...');
      result = await tryAlternativeModels(genAI, enhancedPrompt, imageParts);
    }
    console.log('üì¨ Received response from Gemini API');
    
    const response = await result.response;
    const text = response.text();
    console.log(`üìÑ Response text length: ${text ? text.length : 0} characters`);
    
    if (isVaryRequest) {
      console.log('üîç Enhanced character analysis completed for Vary request');
      console.log(`üìä Analysis preview: ${text.substring(0, 200)}...`);
    }
    console.log('üìã First 200 characters of response:', text ? text.substring(0, 200) + '...' : 'No text received');

    if (!text) {
      return NextResponse.json({
        success: false,
        error: 'No response received from Gemini AI'
      } as CharacterVariationResponse, { status: 500 });
    }

    console.log('üîÑ Parsing Gemini response...');
    console.log(`üìÑ Full Gemini response length: ${text.length} characters`);
    console.log(`üìÑ Response preview (first 500 chars): ${text.substring(0, 500)}...`);
    
    // Parse the response to extract variations
    const variations = parseGeminiResponse(text);
    console.log(`‚úÖ Parsed ${variations.length} variations successfully`);
    
    // Log details of each parsed variation
    variations.forEach((variation, index) => {
      console.log(`üìã Parsed variation ${index + 1}:`, {
        id: variation.id,
        angle: variation.angle,
        pose: variation.pose,
        descriptionLength: variation.description.length,
        descriptionPreview: variation.description.substring(0, 100) + '...'
      });
    });

    if (variations.length === 0) {
      console.log('‚ùå No variations could be parsed from the response');
      return NextResponse.json({
        success: false,
        error: 'Failed to parse character variations from AI response'
      } as CharacterVariationResponse, { status: 500 });
    }

    let variationsWithImages = variations;

    if (hasFalKey) {
      console.log('üé® Generating images with Fal AI...');
      console.log(`üìä Total variations to process: ${variations.length}`);
      console.log(`üîç Background removal mode: ${hasBackgroundRemoval ? 'ENABLED' : 'DISABLED'}`);
      
             // Compress and optimize the primary image for Fal AI
       console.log(`üñºÔ∏è Original image size: ${images[0].length} characters`);
       
       let compressedImage = images[0];
               try {
          // Try to compress the image to reduce size - more conservative for Fal AI
          compressedImage = compressBase64Image(images[0], 200);
          console.log(`üñºÔ∏è Compressed image size: ${compressedImage.length} characters`);
          console.log(`üñºÔ∏è Compression ratio: ${((1 - compressedImage.length / images[0].length) * 100).toFixed(1)}%`);
        } catch (error) {
          console.warn('‚ö†Ô∏è Image compression failed, using original:', error);
        }
       
       // Convert compressed base64 image to data URI for Fal AI
       let primaryImageDataUri = `data:image/jpeg;base64,${compressedImage}`;
       console.log(`üñºÔ∏è Final image data URI length: ${primaryImageDataUri.length} characters`);
       
       // Check if image is still too large for Fal AI
       const maxImageSize = 1000000; // 1MB limit for Fal AI
       if (primaryImageDataUri.length > maxImageSize) {
         console.warn(`‚ö†Ô∏è Image still too large (${primaryImageDataUri.length} chars), attempting further compression`);
         
                   // Try more aggressive compression
          try {
            const aggressiveCompression = compressBase64Image(compressedImage, 100);
            const aggressiveUri = `data:image/jpeg;base64,${aggressiveCompression}`;
            
            if (aggressiveUri.length <= maxImageSize) {
              console.log(`‚úÖ Aggressive compression successful: ${aggressiveUri.length} characters`);
              primaryImageDataUri = aggressiveUri;
            } else {
              console.warn(`‚ö†Ô∏è Image still too large after aggressive compression: ${aggressiveUri.length} characters`);
            }
          } catch (error) {
            console.warn('‚ö†Ô∏è Aggressive compression failed:', error);
          }
       }
      
      // Generate images for each variation using Fal AI
      variationsWithImages = await Promise.all(
        variations.map(async (variation, index) => {
          try {
            console.log(`\nüîÑ === GENERATING IMAGE ${index + 1}/4 ===`);
            console.log(`üìã Variation: ${variation.angle}`);
            console.log(`üìù Pose: ${variation.pose}`);
            console.log(`üìÑ Description length: ${variation.description.length} characters`);
            console.log(`üìÑ Description preview: ${variation.description.substring(0, 100)}...`);
            
            // Sanitize the prompt to avoid content policy violations
            const sanitizedPrompt = sanitizePrompt(variation.description, variation.angle, prompt);
            console.log(`üé® Fal AI prompt for ${variation.angle}:`, sanitizedPrompt);
            console.log(`üìè Sanitized prompt length: ${sanitizedPrompt.length} characters`);
            
            const falResult = await retryWithBackoff(async () => {
              console.log(`üîÑ Attempting Fal AI image generation for ${variation.angle}...`);
              
                             // Use the proper Fal AI editing model that preserves original image style
               const modelName = "fal-ai/nano-banana/edit";
               console.log(`ü§ñ Using Fal AI editing model: ${modelName}`);
               
               // Upload image to temporary URL for nano-banana editing
               const tempImageUrl = await uploadImageToTempUrl(compressedImage);
               
               // Prepare input parameters for nano-banana/edit model
               const inputParams = {
                 prompt: sanitizedPrompt,
                 image_urls: [tempImageUrl], // This model expects image URLs
                 num_images: 1,
                 output_format: "jpeg",
                 // Add specific parameters for background removal and style preservation
                 ...(hasBackgroundRemoval && {
                   negative_prompt: "background, environment, scenery, objects, text, watermark",
                   guidance_scale: 7.5,
                   num_inference_steps: 20
                 }),
                 // Add parameters to preserve original style
                 strength: 0.8, // Keep 80% of original image
                 preserve_style: true, // Preserve the original art style
                 edit_type: "character_variation" // Specify this is a character variation edit
               };
              
              console.log(`‚öôÔ∏è Fal AI input parameters:`, JSON.stringify(inputParams, null, 2));
              console.log(`üîç Background removal parameters included: ${hasBackgroundRemoval ? 'YES' : 'NO'}`);
              
              const startTime = Date.now();
              console.log(`‚è±Ô∏è Starting Fal AI generation at: ${new Date(startTime).toISOString()}`);
              
              const result = await fal.subscribe(modelName, {
                input: inputParams,
                logs: true,
                onQueueUpdate: (update) => {
                  const elapsed = Date.now() - startTime;
                  console.log(`üìä Queue update for ${variation.angle} (${elapsed}ms):`, {
                    status: update.status,
                    ...(update.status === "IN_QUEUE" && { position: (update as any).position }),
                    ...(update.status === "IN_PROGRESS" && { logs: (update as any).logs?.map((log: any) => log.message).join(', ') })
                  });
                  
                  if (update.status === "IN_PROGRESS") {
                    const logs = (update as any).logs;
                    if (logs && Array.isArray(logs)) {
                      console.log(`üìä Generation progress for ${variation.angle}:`, logs.map((log: any) => log.message).join(', '));
                    }
                  }
                },
              });
              
              const endTime = Date.now();
              const totalTime = endTime - startTime;
              console.log(`‚è±Ô∏è Fal AI generation completed in: ${totalTime}ms`);
              
              console.log(`üìä Fal AI response structure:`, {
                hasData: !!result.data,
                hasImages: !!result.data?.images,
                imageCount: result.data?.images?.length || 0,
                responseKeys: Object.keys(result)
              });
              
              if (result.data?.images?.[0]) {
                const image = result.data.images[0];
                console.log(`üñºÔ∏è Generated image details:`, {
                  hasUrl: !!image.url,
                  urlLength: image.url?.length || 0,
                  urlPreview: image.url ? `${image.url.substring(0, 50)}...` : 'No URL',
                  hasWidth: !!image.width,
                  hasHeight: !!image.height,
                  width: image.width,
                  height: image.height
                });
              } else {
                console.log(`‚ö†Ô∏è No image data in Fal AI response for ${variation.angle}`);
                console.log(`üìÑ Full response:`, JSON.stringify(result, null, 2));
              }
              
              return result;
            });

            console.log(`‚úÖ Image ${index + 1} generated successfully for ${variation.angle}`);
            
            // Log the final result structure
            const finalVariation = {
              ...variation,
              imageUrl: falResult.data.images[0]?.url || undefined
            };
            
            console.log(`üìä Final variation ${index + 1} structure:`, {
              id: finalVariation.id,
              angle: finalVariation.angle,
              pose: finalVariation.pose,
              hasImageUrl: !!finalVariation.imageUrl,
              imageUrlLength: finalVariation.imageUrl?.length || 0,
              descriptionLength: finalVariation.description.length
            });
            
            return finalVariation;
          } catch (error) {
            console.error(`‚ùå Failed to generate image for ${variation.angle}:`, error);
            console.error(`‚ùå Error type:`, typeof error);
            console.error(`‚ùå Error name:`, error instanceof Error ? error.name : 'Unknown');
            console.error(`‚ùå Error message:`, error instanceof Error ? error.message : String(error));
            
            if (error instanceof Error && 'body' in error) {
              console.error('‚ùå Full error body:', (error as any).body);
              
              // Check for content policy violation
              const errorBody = (error as any).body;
              if (errorBody?.detail?.[0]?.type === 'content_policy_violation') {
                console.log(`‚ö†Ô∏è Content policy violation for ${variation.angle} - returning text description only`);
                return {
                  ...variation,
                  description: `${variation.description} (Note: Image generation was blocked by content policy - text description only)`
                };
              }
            }
            
            console.log(`‚ö†Ô∏è Returning variation without image URL for ${variation.angle}`);
            return variation; // Return without image URL if generation fails
          }
        })
      );
      
      console.log(`\nüéâ === FAL AI GENERATION COMPLETED ===`);
      console.log(`üìä Total variations processed: ${variationsWithImages.length}`);
      console.log(`‚úÖ Variations with images: ${variationsWithImages.filter(v => v.imageUrl).length}`);
      console.log(`‚ö†Ô∏è Variations without images: ${variationsWithImages.filter(v => !v.imageUrl).length}`);
      
      // Log summary of all variations
      variationsWithImages.forEach((variation, index) => {
        console.log(`üìã Variation ${index + 1}:`, {
          angle: variation.angle,
          pose: variation.pose,
          hasImage: !!variation.imageUrl,
          imageUrlPreview: variation.imageUrl ? `${variation.imageUrl.substring(0, 50)}...` : 'No image'
        });
      });
      
    } else {
      console.log('üìù Returning descriptions only (no FAL_KEY configured)');
    }

    const requestEndTime = Date.now();
    const totalRequestTime = requestEndTime - requestStartTime;
    
    console.log('üéâ API request completed successfully!');
    console.log(`‚è±Ô∏è Total request time: ${totalRequestTime}ms`);
    console.log('üìä Variations with images generated:', variationsWithImages.map(v => v.angle).join(', '));
    
    // Log final summary
    console.log(`\nüìä === FINAL REQUEST SUMMARY ===`);
    console.log(`‚è±Ô∏è Total processing time: ${totalRequestTime}ms`);
    console.log(`üìã Total variations: ${variationsWithImages.length}`);
    console.log(`‚úÖ Variations with images: ${variationsWithImages.filter(v => v.imageUrl).length}`);
    console.log(`‚ö†Ô∏è Variations without images: ${variationsWithImages.filter(v => !v.imageUrl).length}`);
    console.log(`üîç Background removal mode: ${hasBackgroundRemoval ? 'ENABLED' : 'DISABLED'}`);
    
    // Record success for circuit breaker
    recordSuccess();
    
    return NextResponse.json({
      success: true,
      variations: variationsWithImages
    } as CharacterVariationResponse);

  } catch (error) {
    const requestEndTime = Date.now();
    const totalRequestTime = requestEndTime - requestStartTime;
    
    console.error('üí• Error in vary-character API:', error);
    console.error(`‚è±Ô∏è Request failed after: ${totalRequestTime}ms`);
    console.error('üí• Error type:', typeof error);
    console.error('üí• Error name:', error instanceof Error ? error.name : 'Unknown');
    console.error('üí• Error message:', error instanceof Error ? error.message : String(error));
    
    // Record failure for circuit breaker
    recordFailure();
    
    let errorMessage = 'An unexpected error occurred';
    let statusCode = 500;
    
         if (error instanceof Error) {
       errorMessage = error.message;
       console.error('üí• Full error stack:', error.stack);
       
       // Provide more specific error messages for common failure scenarios
       if (error.message.includes('503 Service Unavailable') || error.message.includes('model is overloaded')) {
         errorMessage = 'The AI service is currently overloaded. Please try again in a few moments.';
         statusCode = 503;
       } else if (error.message.includes('rate limit exceeded') || error.message.includes('quota exceeded')) {
         errorMessage = 'API rate limit exceeded. Please try again later.';
         statusCode = 429;
       } else if (error.message.includes('invalid api key') || error.message.includes('authentication')) {
         errorMessage = 'Authentication failed. Please check your API configuration.';
         statusCode = 401;
       } else if (error.message.includes('content policy violation')) {
         errorMessage = 'The request was blocked due to content policy violations.';
         statusCode = 400;
       } else if (error.message.includes('timeout') || error.message.includes('network error')) {
         errorMessage = 'Request timed out. Please check your connection and try again.';
         statusCode = 408;
       } else if (error.message.includes('413') || error.message.includes('Request Entity Too Large')) {
         errorMessage = 'The image file is too large. Please try with a smaller image or compress the image before uploading.';
         statusCode = 413;
       }
     }

    return NextResponse.json({
      success: false,
      error: errorMessage,
      retryable: statusCode === 503 || statusCode === 429 || statusCode === 408
    } as CharacterVariationResponse, { status: statusCode });
  }
}

function parseGeminiResponse(text: string): CharacterVariation[] {
  const variations: CharacterVariation[] = [];
  
  try {
    // Split the response into sections (looking for numbered variations or clear separators)
    const sections = text.split(/(?:\d+\.|Variation \d+|###|\n\n\n)/g)
      .filter(section => section.trim().length > 50); // Filter out short/empty sections

    let variationCount = 0;
    const maxVariations = 4;

    for (const section of sections) {
      if (variationCount >= maxVariations) break;
      
      const trimmedSection = section.trim();
      if (trimmedSection.length < 50) continue; // Skip very short sections

      // Extract angle/view information (look for common angle terms)
      const angleKeywords = ['side', 'front', 'back', 'profile', 'angle', 'view', 'perspective', 'pose', 'stance'];
      const lines = trimmedSection.split('\n').filter(line => line.trim());
      
      let angle = 'Character View';
      let pose = 'Standard Pose';
      
      // Try to find angle and pose in the first few lines
      for (let i = 0; i < Math.min(3, lines.length); i++) {
        const line = lines[i].toLowerCase();
        if (angleKeywords.some(keyword => line.includes(keyword))) {
          if (line.includes('side') || line.includes('profile')) {
            angle = 'Side Profile View';
          } else if (line.includes('back')) {
            angle = 'Back View';
          } else if (line.includes('front')) {
            angle = 'Front View';
          } else if (line.includes('3/4') || line.includes('quarter')) {
            angle = '3/4 Angle View';
          } else if (line.includes('action') || line.includes('dynamic')) {
            angle = 'Action View';
            pose = 'Dynamic Action Pose';
          } else {
            angle = lines[i].trim().length > 0 ? lines[i].trim() : angle;
          }
          break;
        }
      }

      // If we couldn't determine a specific angle, assign based on variation number
      if (angle === 'Character View') {
        const defaultAngles = ['Front View', 'Side Profile', '3/4 Angle View', 'Back View'];
        angle = defaultAngles[variationCount] || `Variation ${variationCount + 1}`;
      }

      variations.push({
        id: `variation-${variationCount + 1}`,
        description: trimmedSection,
        angle: angle,
        pose: pose
      });

      variationCount++;
    }

    // If we didn't get enough variations, try a different parsing approach
    if (variations.length < 2) {
      // Fallback: split by paragraphs and take the longest ones
      const paragraphs = text.split('\n\n')
        .filter(p => p.trim().length > 100)
        .slice(0, 4);

      variations.length = 0; // Clear previous attempts

      paragraphs.forEach((paragraph, index) => {
        const defaultAngles = ['Front View', 'Side Profile', '3/4 Angle View', 'Back View'];
        const defaultPoses = ['Standard Stance', 'Profile Pose', 'Angled Stance', 'Rear View Pose'];
        
        variations.push({
          id: `variation-${index + 1}`,
          description: paragraph.trim(),
          angle: defaultAngles[index] || `View ${index + 1}`,
          pose: defaultPoses[index] || `Pose ${index + 1}`
        });
      });
    }

    // Ensure we have at least 4 variations, even if we need to create fallbacks
    while (variations.length < 4) {
      const index = variations.length;
      const fallbackAngles = ['Front View', 'Side Profile', '3/4 Angle View', 'Back View'];
      const fallbackPoses = ['Standard Stance', 'Profile Pose', 'Angled Stance', 'Rear View Pose'];
      
      variations.push({
        id: `variation-${index + 1}`,
        description: `Character variation ${index + 1}: Show the same character from a ${fallbackAngles[index].toLowerCase()} with ${fallbackPoses[index].toLowerCase()}. Maintain all original design elements, clothing, and features while changing the viewing angle and pose.`,
        angle: fallbackAngles[index],
        pose: fallbackPoses[index]
      });
    }

    return variations.slice(0, 4); // Ensure exactly 4 variations

  } catch (error) {
    console.error('Error parsing Gemini response:', error);
    
    // Return fallback variations if parsing completely fails
    return [
      {
        id: 'variation-1',
        description: 'Front view of the character maintaining original design and features.',
        angle: 'Front View',
        pose: 'Standard Stance'
      },
      {
        id: 'variation-2',
        description: 'Side profile view of the character with same clothing and style.',
        angle: 'Side Profile',
        pose: 'Profile Pose'
      },
      {
        id: 'variation-3',
        description: '3/4 angle view showing character from diagonal perspective.',
        angle: '3/4 Angle View',
        pose: 'Angled Stance'
      },
      {
        id: 'variation-4',
        description: 'Back view of the character showing rear perspective.',
        angle: 'Back View',
        pose: 'Rear View Pose'
      }
    ];
  }
}